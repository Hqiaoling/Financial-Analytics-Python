# -*- coding: utf-8 -*-
"""Huang_Qiaoling_HW02.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qMJssAx2ac0Ea7roFwpvKg312Dlox_fQ

# HW 02 - Use pandas and sklearn to understand the Titanic data

<font color=blue size=4>
Before you submit this assignment, please carefully read these submission instructions. You must name this .ipynb file:
<br><br>
yourlastname_yourfirstname_HW2.ipynb
<br><br>
You must turn in this assignment by uploading the 
.ipynb file to the assignment on questrom tools. You will also need to print out a hard copy of this notebook (File->Print from colab) with the output from running all the code cells, and hand it in on the class following the due date. Do not email me the file.
<br><br>
Points will be deducted for improper submission!
</font>

For this Homework Assignment, we will be applying our knowledge of Pandas and Sklearn to an interesting dataset about the survival of passengers on the Titanic.


The dataset describes those onboard the titanic that survived and did not, in terms of many of their attributes, such as:
- the passenger's ticket class (pclass, class)
- sex and age
- the fare they paid for their ticket (fare)
- the town they embarked from (embark_town, embarked)
- whether they had siblings on board (sibsp)
- if they were a parent, the number of chidron on board (or if they are a child, the number of parents on board) (parch) 

Unlike the example in class, we won't be starting with a cleaned dataset, but with the full dataset that is available via the seaborn package. 

Run the code cell below  to load the dataset:
"""

import pandas as pd
import numpy as np
import seaborn as sns
titanic=sns.load_dataset('titanic')
titanic.head()

"""Q: Before analyzing the data, remove rows where  age is NaN."""

#titanic.age.isnull().sum()
titanic.dropna(subset=['age'], inplace=True)

"""Q: Make a new column named `adult` thats is equal to 0  when "age" is less than 18 and equal to 1 otherwise."""

def adult(titanic):
  if titanic['age'] < 18:
    return 0
  else:
    return 1

titanic['adult']=titanic.apply(adult, axis=1)

titanic.head()

"""Q: Convert "female" to 0 and "male" to 1 in the "sex" column"""

def sex(titanic):
  if titanic['sex'] == "female":
    return 0
  else:
    return 1

titanic['sex'] = titanic.apply(sex, axis=1)

titanic.head()

"""The dataset is now cleaned and ready for you to run some analysis.

Print the shape of the cleaned data. **Hereafter, all answers should be drawn from the cleaned data.**
"""

print(titanic.shape)

"""The goal of this homework is to build classifiers that predict whether a passenger is alive, based on data features.

Q: Determine the mean survivors by `sex` and `adult` (simultaneously). Your answer should return a 2x2 dataframe with the rows indexed by `sex` and two columns (for `adult`=0 and `adult`=1). You should not use any explicit loops or `apply` to accomplish this:
"""

titanic.groupby(['sex', 'adult']).survived.mean().unstack()

"""You can see significant differences in survival rate by sex and age, indicating classifiers built with "sex" and "adult" columns would work well.

Q: Define a new dataframe `X` that contains the `sex` and `adult` columns of the data and a pandas series `y` that is equal to the `survived` column.
"""

X = pd.DataFrame(titanic, columns =['sex', 'adult'])
print(X.head())
y = pd.Series(titanic['survived'])
print(y.head())

"""Q: Split `X` and `y` into train (80%) and test (20%) sets. Assign `random_state=0` when you split."""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)

"""**Now, by referring to the official scikit-learn documentation, build two classifiers using K Nearest Neighbors (KNN) and Naive Bayes.**

Q: Build a KNN classifier with n_neighbors=2 and fit it to the training data
"""

from sklearn.neighbors import KNeighborsClassifier
# Create KNN classifier
knn = KNeighborsClassifier(n_neighbors = 2)
# Fit the classifier to the data
knn.fit(X_train,y_train)

"""Q. What is the accuracy_score of the KNN classifier with n_neighbors=2? Print it out."""

from sklearn.metrics import accuracy_score
y_pred = knn.predict(X_test)
#check accuracy of our model on the test data
print('accuracy_score:{}'.format(accuracy_score(y_test, y_pred)))

"""The accuracy we obtained is from just one random split of the data. Instead, we can use **cross-fold validation** by using the `cross_val_score` method from `sklearn.model_selection`. Import this and refer to the documentation to get the scores from a cross-fold validation with `cv=5` and the default `scoring` (i.e., don't change this parameter). Note that we do not need to split the data into training and test, but pass the entire features and target to `cross_val_score`. Print the mean and standard deviation of the scores:"""

from sklearn.model_selection import cross_val_score
import numpy as np
knn_cv = KNeighborsClassifier(n_neighbors=2)
knn_cv_scores = cross_val_score(knn_cv, X, y, cv=5)
print('cv_scores mean:{}'.format(np.mean(knn_cv_scores)))
print('cv_scores standard deviation:{}'.format(knn_cv_scores.std()))

"""Q: Now build a Naive Bayes classifier with `GaussianNB` (from `sklearn.naive_bayes`) by referring to the documentation. Use cross-fold validation as before and print out the mean and standard deviation of the scores:"""

from sklearn.naive_bayes import GaussianNB
nb_cv = GaussianNB()
nb_cv_scores = cross_val_score(nb_cv, X, y, cv=5)
print('nb_cv_scores mean:{}'.format(np.mean(nb_cv_scores)))
print('nb_cv_standard deviation:{}'.format(nb_cv_scores.std()))

"""Q: Which classifier has a higher mean score, the KNN classifier with n_neighbors=2 or the Naive Bayes classifier? Double click the text cell below and enter your answer.

Naive Bayers classifier has a higher mean score which is 0.7731409435634788.
"""